{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "997ae2a3-4faa-4a71-9cb4-7a850431b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df989b0e-0614-401d-8d60-a62383c3d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports_notebook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07dc21fd-32ca-4212-8d6f-0e20ca3886ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c21bd9ec-b927-417b-adb9-d8483ca27da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (91920 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "with open('murder.txt') as f:\n",
    "    text_book = f.read()\n",
    "    text_book = ' '.join(text_book.split())\n",
    "    tokens_str_book = tokenizer.tokenize(text_book)\n",
    "    input_ids_book = tokenizer(text_book, return_tensors='pt').input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2926855-33d9-4b52-be29-89806e4da6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91920"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "23babf8f-342f-4589-b6e1-9c79f82b3843",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_layer = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63233bbf-3094-410b-909a-0062ac6f94ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5118783-cb6e-4ac3-9cb7-b3ee06ead134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.931952476501465\n",
      "6.80461311340332\n",
      "8.953631401062012\n",
      "18.184497833251953\n",
      "6.042055130004883\n",
      "5.946381568908691\n",
      "8.287891387939453\n",
      "6.885945796966553\n",
      "7.439345359802246\n",
      "6.579103469848633\n",
      "6.082755088806152\n",
      "5.4809112548828125\n",
      "5.181005954742432\n",
      "4.827835559844971\n",
      "4.783973693847656\n",
      "4.627377510070801\n",
      "4.498370170593262\n",
      "4.453348636627197\n",
      "4.467597961425781\n",
      "4.302306175231934\n",
      "4.259462356567383\n",
      "4.141630172729492\n",
      "4.131664276123047\n",
      "4.03169059753418\n",
      "4.038936614990234\n",
      "3.9035935401916504\n",
      "3.886910915374756\n",
      "3.953803539276123\n",
      "3.87528133392334\n",
      "3.902590036392212\n",
      "3.8031630516052246\n",
      "3.6196298599243164\n",
      "3.649967670440674\n",
      "3.570722818374634\n",
      "3.818276882171631\n",
      "3.9187307357788086\n",
      "3.9427261352539062\n",
      "3.7300281524658203\n",
      "3.5436630249023438\n",
      "3.8783302307128906\n",
      "3.7880985736846924\n",
      "3.9288463592529297\n",
      "3.985140085220337\n",
      "3.5719099044799805\n",
      "3.978423595428467\n",
      "3.5593481063842773\n",
      "3.765357494354248\n",
      "3.6991231441497803\n",
      "3.637214183807373\n",
      "3.54717755317688\n",
      "3.5469071865081787\n",
      "3.486161708831787\n",
      "3.740703582763672\n",
      "3.4008171558380127\n",
      "3.4325523376464844\n",
      "3.435971260070801\n",
      "3.5281503200531006\n",
      "3.336130142211914\n",
      "3.444287061691284\n",
      "3.560288429260254\n",
      "3.3388333320617676\n",
      "3.4234485626220703\n",
      "3.654686450958252\n",
      "3.250009775161743\n",
      "3.3676669597625732\n",
      "3.386261463165283\n",
      "3.3169596195220947\n",
      "3.2925028800964355\n",
      "3.3311243057250977\n",
      "3.2327733039855957\n",
      "3.3124911785125732\n",
      "3.2614598274230957\n",
      "3.3265035152435303\n",
      "3.2479395866394043\n",
      "3.472597122192383\n",
      "3.165029525756836\n",
      "3.5978500843048096\n",
      "3.1390275955200195\n",
      "3.5072903633117676\n",
      "3.0889058113098145\n",
      "3.5774455070495605\n",
      "3.3353018760681152\n",
      "3.5148191452026367\n",
      "3.401962995529175\n",
      "3.1705410480499268\n",
      "3.6309337615966797\n",
      "3.1674036979675293\n",
      "3.347142219543457\n",
      "3.348167657852173\n"
     ]
    }
   ],
   "source": [
    "predictor = nn.Sequential(\n",
    "    nn.Linear(768, 1024),\n",
    "    nn.GELU(),\n",
    "    nn.Linear(1024, 1024),\n",
    "    nn.GELU(),\n",
    "    nn.Linear(1024, 1024),\n",
    "    nn.GELU(),\n",
    "    nn.Linear(1024, 1024),\n",
    ")\n",
    "                          \n",
    "predictor = predictor.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(predictor.parameters(), lr=1e-2)\n",
    "\n",
    "for idx_start in range(0, len(input_ids_book)-1024, 1024):\n",
    "    idx = torch.arange(1024)+idx_start\n",
    "    # # idx = (1024*torch.arange(50))[:, None] + idx\n",
    "    input_ids = input_ids_book[idx].to(device)\n",
    "    ak = {'debug': True}\n",
    "    model(input_ids, ak=ak)\n",
    "    Q, K, V = ak['QKV']\n",
    "    Q = Q.permute(0, 1, 3, 2, 4).reshape(-1, 6, 1024, 64*12)[:, idx_layer]\n",
    "    \n",
    "    y = predictor(Q)\n",
    "    yp = torch.arange(1024)[None, :].to(device)\n",
    "    loss = loss_fn.forward(y, yp)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c22a48-a462-49a3-9f4b-ffc296c91d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2478c4-4ea0-4869-a33d-fa5e9c7c843f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837019bf-e9b7-486f-b31b-188095aad85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bb410b-73d4-420c-91b7-55ee97c47dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a598b27d-44b3-4f49-97e9-09881f8a9911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
